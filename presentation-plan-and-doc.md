# Explorer Hadoop: du stockage aux traitements
## Introduction
Hadoop est un framework open source qui permet de stocker et de traiter de très grands volumes de données de manière distribuée, grace aux clusters de machines.
Un cluster de machine, qu'est ce que c'est? Il désigne un ensemble de serveurs physiques ou virtuels interconnectés et coordonnés pour fonctionner comme une seule entité: 
chaque machine ou noeud participe au stockage et au calcul.
Hadoop gère aussi bien les données structurées (tableurs, bases de données) que non structurées (logs, documents texte, images), 
grâce à son système de fichiers distribué (HDFS) et à son moteur de traitement parallèle (YARN + MapReduce).
### Objectifs - Plan
Dans cette présentation, nous allons  explorer les concepts clés d’Hadoop et son positionnement dans l’écosystème Big Data,
comprendre l’architecture : HDFS pour le stockage et YARN pour la gestion des ressources, 
découvrir le modèle MapReduce : introduction au paradigme « map » et « reduce », et façon dont Hadoop orchestre l’exécution de vos fonctions métier sur chaque nœud.
et enfin voir en pratique une démonstration WordCount, l’exemple classique de MapReduce, pour illustrer en direct comment écrire, lancer et visualiser un job sur un cluster Hadoop.

## Plan de la présentation

## 